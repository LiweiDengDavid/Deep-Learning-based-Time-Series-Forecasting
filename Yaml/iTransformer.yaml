channel_independence_itransformer:  False # whether to use channel_independence mechanism
inverse: False # inverse output data
class_strategy: 'projection' # 'projection/average/cls_token'
use_norm_itransformer: True #use norm and denorm

# iTransformer
#parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')
#parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')
#parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')
#parser.add_argument('--factor', type=int, default=1, help='attn factor')
#parser.add_argument('--distil', action='store_false',
#                   help='whether to use distilling in encoder, using this argument means not using distilling',
#                    default=True)
#parser.add_argument('--embed', type=str, default='timeF',
#                    help='time features encoding, options:[timeF, fixed, learned]')
#parser.add_argument('--activation', type=str, default='gelu', help='activation')
#parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')

